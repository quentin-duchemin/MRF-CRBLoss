{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive tool for estimation of parameters in quantitative MRI\n",
    "\n",
    "# Visualization of the results : $\\color{red}{\\text{OFFLINE FRAMEWORK}}$ \n",
    "\n",
    "## Visiting Student : Quentin Duchemin\n",
    "## Profesors : Carlos Fernandez Granda & Jakob Assländer\n",
    "\n",
    "\n",
    "\n",
    "### 1) Presentation of the project\n",
    "\n",
    "We try to estimate the biological parameters in quantitative MRI using neural networks. This notebook is an interactive tool allowing you to visualize the results of your trainings. Make sure that you want to use fingerprints that are computed $\\color{red}{\\text{OFFLINE}}$.\n",
    "\n",
    "### 2) How to use this interface ?\n",
    "\n",
    "This tool allows to visualize the results of training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ipywidgets\n",
    "! jupyter nbextension enable --py widgetsnbextension\n",
    "! pip install seaborn\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import importlib\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sc\n",
    "import scipy.io\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from MRF.Training_parameters import *\n",
    "from MRF.BaseModel import *\n",
    "from MRF.Projection import *\n",
    "from MRF.models import *\n",
    "import MRF\n",
    "from MRF.Offline import Network, Data_class, Performances\n",
    "from MRF.Training_parameters import *\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL = 'ALL'\n",
    "def unique_sorted_values_plus_ALL(array):\n",
    "    unique = array.unique().tolist()\n",
    "    unique.sort()\n",
    "    unique.insert(0, ALL)\n",
    "    return unique\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "fnetworks = [f for f in listdir('../save_networks_offline') if isfile(join('../save_networks_offline', f))]\n",
    "exclude = ('num_files_validation','device','NN','urls','gradients','training_absolute_errors','training_relative_errors','losses_validation','params_validation','t','x','validation_absolute_errors','validation_relative_errors','small_validation_relative_errors','dico_validation','losses','losses_small_validation','losses_small_validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24f313830be43d3aeec3b9f04a61624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(interactive(children=(Dropdown(description='Chosen network: ', layout=Layout(wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "item_layout = widgets. Layout(\n",
    "    display='flex',\n",
    "    justify_content='space-between'\n",
    ")\n",
    "style = {'description_width': '250px'}\n",
    "layout = {'width': '500px'}\n",
    "\n",
    "def moving_average(a, n=3) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "def print_inventory(dct):\n",
    "    print(\"SETTINGS:\")\n",
    "    for item, amount in dct.items():\n",
    "        print(\"{} ({})\".format(item, amount))\n",
    "        \n",
    "def gram_schmidt(V):\n",
    "    n,r = V.shape\n",
    "    Vortho = np.zeros((n,r))\n",
    "    Vortho[:,0] = V[:,0] / np.linalg.norm(V[:,0])\n",
    "    for i in range(1,r):\n",
    "        Vortho[:,i] = V[:,i]\n",
    "        for j in range(i):\n",
    "            Vortho[:,i] -= np.vdot(Vortho[:,j],V[:,i]) * Vortho[:,j]\n",
    "        Vortho[:,i] /= np.linalg.norm(Vortho[:,i])\n",
    "    return Vortho\n",
    "    \n",
    "def common_filtering(net, name, type_plot, mvavg=1, indice=1, folder='Offline', num=0, freqcut=10000, para_abs=2, para_ordo=1, para_error=1):\n",
    "    model = importlib.import_module('MRF.models.'+net['name_model'])\n",
    "    PLOT.clear_output()\n",
    "    with open('../settings_files_offline/settings_'+name.replace('network_','')+'.pkl', 'rb') as f:\n",
    "        settings = pickle.load(f)\n",
    "        training_parameters = Training_parameters(settings['batch_size'], 1, settings['nb_epochs'], settings['params'], settings['normalization'])\n",
    "        projection = Projection(settings['start_by_projection'], settings['dimension_projection'], settings['initialization'], settings['normalization'], settings['namepca'])\n",
    "        data_class = Data_class(training_parameters, settings['noise_type'], settings['noise_level'], \n",
    "                                       settings['minPD'], settings['maxPD'], settings['nb_files'], settings['path_files'])\n",
    "        validation_settings = {'validation': settings['validation'],'small_validation_size': settings['small_validation_size'], 'validation_size': settings['validation_size']}\n",
    "        netw = model.model(projection=projection,nb_params=len(settings['params']))\n",
    "        device = torch.device('cpu')\n",
    "        netw.load_state_dict(net['NN'])\n",
    "        netw.eval()\n",
    "        estimation = Network(settings['model'], settings['loss'], training_parameters, settings['save_name'], data_class, validation_settings, projection=projection)\n",
    "    with PLOT:\n",
    "        if type_plot == 'settings':\n",
    "            d = dict((k,net[k]) for k in net.keys() if k not in exclude)\n",
    "            print_inventory(d)\n",
    "\n",
    "        elif type_plot == 'first_layer':\n",
    "            sns.set()\n",
    "            layer = np.array(netw.fc1.weight.data)\n",
    "            n,m = layer.shape\n",
    "            c = 0\n",
    "            fig, ax = plt.subplots(nrows=int((n+1)//2), ncols=2, figsize=(10,35))  \n",
    "            for i in range(n):\n",
    "                c += 1\n",
    "                c = c % 2\n",
    "                ax[i//2,c].plot(layer[i,:])\n",
    "                ax[i//2,c].set_xlabel('time (in s.)')\n",
    "            plt.show()\n",
    "\n",
    "            button = widgets.Button(description=\"CLICK HERE to save those weights !\", layout=widgets.Layout(width='50%', height='80px'))\n",
    "            output = widgets.Output()\n",
    "            display(button, output)\n",
    "            def on_button_clicked(b):\n",
    "                with output:\n",
    "                    sc.io.savemat('weights_first_layer.mat',layer)\n",
    "                    sc.io.savemat('weights_first_layer_orthonormal.mat',gram_schmidt(layer.T).T)\n",
    "            button.on_click(on_button_clicked)\n",
    "            \n",
    "        elif type_plot == 'Basis functions for the projection subspace':\n",
    "            \n",
    "            from scipy.fftpack import fft, ifft, fftfreq\n",
    "            \n",
    "            layer = np.array(netw.fc1.weight.data)\n",
    "            n,m = layer.shape\n",
    "            u,s,vt = np.linalg.svd(layer)\n",
    "            n,m = u.shape\n",
    "            W = fftfreq(vt.shape[1], d=1) \n",
    "            c = 0\n",
    "            fig, ax = plt.subplots(nrows=int((n+1)//2), ncols=2, figsize=(10,35))  \n",
    "            for i in range(n):\n",
    "                f_signal = fft(vt[i,:])\n",
    "                # If our original signal time was in seconds, this is now in Hz    \n",
    "                cut_f_signal = f_signal.copy()\n",
    "                cut_f_signal[(np.abs(W)>freqcut)] = 0\n",
    "\n",
    "                cut_signal = ifft(cut_f_signal)\n",
    "                c += 1\n",
    "                c = c % 2\n",
    "                ax[i//2,c].plot(cut_signal)\n",
    "                ax[i//2,c].set_xlabel('time (in s.)')\n",
    "            plt.show()\n",
    "\n",
    "        elif type_plot == 'NN VS NLLS and CRB':\n",
    "            MEANnlls, STDnlls, MEANnet, STDnet, CRBs, trueparams = estimation.local_study(netw, os.path.join('../noise_files', folder))\n",
    "            pos = [i+1 for i in range(len(estimation.trparas.params))]\n",
    "            bars = ('CRB','NN', 'NLLS')\n",
    "            params = estimation.trparas.params\n",
    "            nbparams = len(params)\n",
    "            if num > CRBs.shape[0]:\n",
    "                print('No fingerprint exists for this number. To see only one fingerprint, choose a number between 0 and '+str(CRBs.shape[0]-1)+'. Here we plot all the fingerprints.')\n",
    "                for numero in range(CRBs.shape[0]):\n",
    "                    print('True parameters', trueparams[numero,:])\n",
    "                    plt.figure(figsize=(4*nbparams,3))\n",
    "                    \n",
    "                    for j in range(nbparams):\n",
    "                        plt.style.use('seaborn-white')\n",
    "                        plt.subplot(1,nbparams,j+1)\n",
    "                        plt.ylabel(paramtoname[params[j]]) # CRBs[numero,j]\n",
    "                        plt.errorbar(1, trueparams[numero,params[j]],0.0001, fmt='o', color='black', ecolor='lightgray', elinewidth=3, capsize=0, label='CRB')\n",
    "                        plt.errorbar(2, MEANnet[numero,j], STDnet[numero,j], fmt='o', color='red', ecolor='lightgray', elinewidth=3, capsize=0, label='NN')\n",
    "                        plt.errorbar(3, MEANnlls[numero,j], STDnlls[numero,j], fmt='o', color='green', ecolor='lightgray', elinewidth=3, capsize=0, label='NLLS')\n",
    "                        plt.xticks(pos, bars)\n",
    "                        plt.tight_layout()\n",
    "                    plt.show()\n",
    "            else:\n",
    "                plt.figure(figsize=(12,3))\n",
    "                params = estimation.trparas.params\n",
    "                nbparams = len(params)\n",
    "                print('True parameters', trueparams[num,:])\n",
    "\n",
    "                for j in range(nbparams):\n",
    "                    plt.style.use('seaborn-white')\n",
    "                    plt.subplot(1,nbparams,j+1)\n",
    "                    plt.ylabel(paramtoname[params[j]])#CRBs[num,j]\n",
    "                    plt.errorbar(1, trueparams[num,params[j]], 0.0001, fmt='o', color='black', ecolor='lightgray', elinewidth=3, capsize=0, label='CRB')\n",
    "                    plt.errorbar(2, MEANnet[num,j], STDnet[num,j], fmt='o', color='red', ecolor='lightgray', elinewidth=3, capsize=0, label='NN')\n",
    "                    plt.errorbar(3, MEANnlls[num,j], STDnlls[num,j], fmt='o', color='green', ecolor='lightgray', elinewidth=3, capsize=0, label='NLLS')\n",
    "                    plt.xticks(pos, bars)\n",
    "                    plt.tight_layout()\n",
    "                plt.show()\n",
    "                for j in range(nbparams):\n",
    "                    print(paramtoname[params[j]]+' :',trueparams[num,params[j]])\n",
    "                    print('                      sqrt{CRB} : ', round(CRBs[num,j],4) )\n",
    "                    print('NEURAL NETWORK mean : ', round(MEANnet[num,j],4), '    std : ', round(STDnet[num,j],4), '    sqrt{CRB} / std   : ', round(CRBs[num,j]/np.float(STDnet[num,j]),4) )\n",
    "                    print('NON LINEAR LS  mean : ', round(MEANnlls[num,j],4), '    std : ', round(STDnlls[num,j],4), '    sqrt{CRB} / std   : ',round( CRBs[num,j]/np.float(STDnlls[num,j]),4) )\n",
    "                    print('\\n')\n",
    "                    print('\\n')\n",
    "\n",
    "        elif type_plot == 'relative errors':\n",
    "            plt.figure(figsize=(12,5*len(net['params'])))\n",
    "            plt.style.use('seaborn-whitegrid')\n",
    "            for i in range(len(net['params'])):\n",
    "                if len(net['params'])==1:\n",
    "                    if net['validation']:\n",
    "                        val_relerrors = moving_average(np.array(net['validation_relative_errors'])[indice:], n=mvavg)\n",
    "                    train_relerrors = np.array(net['training_relative_errors'])[indice:]\n",
    "                else:\n",
    "                    if net['validation']:\n",
    "                        val_relerrors = moving_average(np.array(net['validation_relative_errors'])[indice:,i], n=mvavg)\n",
    "                    train_relerrors = np.array(net['training_relative_errors'])[indice:,i]\n",
    "                train_relerrors = moving_average(train_relerrors, n=mvavg)\n",
    "                size = train_relerrors.shape[0]\n",
    "                plt.subplot(len(net['params']),1,i+1)\n",
    "                absc = [mvavg+indice + j for j in range(size)]\n",
    "                plt.plot(absc,train_relerrors, label='training')\n",
    "                if net['validation']:\n",
    "                    plt.plot(absc, val_relerrors, label='validation')\n",
    "                plt.legend()\n",
    "                plt.title('Relative error on '+paramtoname[net['params'][i]] +' along epochs',size=20)\n",
    "                plt.xlabel('Epochs')\n",
    "            plt.show()\n",
    "            \n",
    "        elif type_plot == 'absolute errors':\n",
    "            plt.figure(figsize=(12,5*len(net['params'])))\n",
    "            plt.style.use('seaborn-whitegrid')\n",
    "            for i in range(len(net['params'])):\n",
    "                if len(net['params'])==1:\n",
    "                    if net['validation']:\n",
    "                        val_relerrors = moving_average(np.array(net['validation_absolute_errors'])[indice:], n=mvavg)\n",
    "                    train_relerrors = np.array(net['training_absolute_errors'])[indice:]\n",
    "                else:\n",
    "                    if net['validation']:\n",
    "                        val_relerrors = moving_average(np.array(net['validation_absolute_errors'])[indice:,i], n=mvavg)\n",
    "                    train_relerrors = np.array(net['training_absolute_errors'])[indice:,i]\n",
    "                train_relerrors = moving_average(train_relerrors, n=mvavg)\n",
    "                size = train_relerrors.shape[0]\n",
    "                plt.subplot(len(net['params']),1,i+1)\n",
    "                absc = [mvavg+indice + j for j in range(size)]\n",
    "                plt.plot(absc,train_relerrors, label='training')\n",
    "                if net['validation']:\n",
    "                    plt.plot(absc, val_relerrors, label='validation')\n",
    "                plt.legend()\n",
    "                plt.title('absolute error on '+paramtoname[net['params'][i]] +' along epochs',size=20)\n",
    "                plt.xlabel('Epochs')\n",
    "            plt.show()\n",
    "            \n",
    "        elif type_plot == 'absolute errors over CRBs':\n",
    "            plt.figure(figsize=(12,5*len(net['params'])))\n",
    "            plt.style.use('seaborn-whitegrid')\n",
    "            for i in range(len(net['params'])):\n",
    "                if len(net['params'])==1:\n",
    "                    if net['validation']:\n",
    "                        val_relerrors = moving_average(np.array(net['validation_absolute_errors_over_CRBs'])[indice:], n=mvavg)\n",
    "                    train_relerrors = np.array(net['training_absolute_errors_over_CRBs'])[indice:]\n",
    "                else:\n",
    "                    if net['validation']:\n",
    "                        val_relerrors = moving_average(np.array(net['validation_absolute_errors_over_CRBs'])[indice:,i], n=mvavg)\n",
    "                    train_relerrors = np.array(net['training_absolute_errors_over_CRBs'])[indice:,i]\n",
    "                train_relerrors = moving_average(train_relerrors, n=mvavg)\n",
    "                size = train_relerrors.shape[0]\n",
    "                plt.subplot(len(net['params']),1,i+1)\n",
    "                absc = [mvavg+indice + j for j in range(size)]\n",
    "                plt.plot(absc,train_relerrors, label='training')\n",
    "                if net['validation']:\n",
    "                    plt.plot(absc, val_relerrors, label='validation')\n",
    "                plt.legend()\n",
    "                plt.title('absolute error on '+paramtoname[net['params'][i]] +' along epochs',size=20)\n",
    "                plt.xlabel('Epochs')\n",
    "            plt.show()\n",
    "            \n",
    "        elif type_plot == 'Singular values projection layer':\n",
    "            layer = np.array(netw.fc1.weight.data)\n",
    "            n,m = layer.shape\n",
    "            sns.set()\n",
    "            layer = np.array(netw.fc1.weight.data)\n",
    "            u, s, vt = np.linalg.svd(layer)\n",
    "            plt.plot(s)\n",
    "            plt.xlabel('Number of the singular values')\n",
    "            plt.ylabel('Singular values of the first linear layer')\n",
    "            plt.title('Singular values of the projection layer', size=18)\n",
    "            plt.show()\n",
    "\n",
    "        elif type_plot == 'error':\n",
    "            paraabs, paraordo, paraerror = nametoparam[para_abs][0], nametoparam[para_ordo][0], nametoparam[para_error][0]\n",
    "\n",
    "            if paraerror not in net['params']:\n",
    "                print('The parameter chosen for the error was not estimated for this training.')\n",
    "            else:\n",
    "                VP = net['params_validation']\n",
    "                indices = np.where(VP[:,0]>=-0.3)[0]\n",
    "                VP = VP[indices,:]\n",
    "                VPerrors = np.zeros((VP.shape[0]))\n",
    "                with torch.no_grad():\n",
    "                    outputs = netw(net['dico_validation'])[indices,:]\n",
    "                    ind = net['params'].index(paraerror)\n",
    "                    VPerrors = np.abs(estimation.transform(outputs[:,ind], paraerror)-VP[:,paraerror])/VP[:,paraerror]\n",
    "                VP, VPerrors = np.array(VP), np.array(VPerrors)\n",
    "                args = np.argsort(VPerrors)\n",
    "                sns.set_style(\"ticks\")        \n",
    "                fig , ax = plt.subplots(nrows=3, ncols=1, figsize=(10,18))\n",
    "                sc = ax[0].scatter(VP[args[-100:],paraabs], VP[args[-100:],paraordo], c=VPerrors[args[-100:]], s=100, edgecolor='')\n",
    "                plt.colorbar(sc, ax=ax[0])\n",
    "                ax[0].set_xlabel(para_abs, fontsize=15)\n",
    "                ax[0].set_ylabel(para_ordo, fontsize=15)\n",
    "                ax[0].set_title('100 worst relative errors in validation for '+para_error, fontsize=20)\n",
    "                sns.distplot(VP[args[-100:],paraerror], hist=True, kde=True, \n",
    "                             bins=int(180/5), color = 'darkblue', \n",
    "                             hist_kws={'edgecolor':'black'}, kde_kws={'linewidth': 4}, \n",
    "                             label='Keeping the 100 samples with highest relative error', ax=ax[1])\n",
    "                sns.distplot(VP[:,paraerror], hist=True, kde=True, \n",
    "                             bins=int(180/5), color = 'darkred', \n",
    "                             hist_kws={'edgecolor':'black'}, kde_kws={'linewidth': 4},\n",
    "                             label='On the whole validation dataset',ax=ax[1])\n",
    "                ax[1].set_xlabel(para_error, fontsize=15)\n",
    "                ax[1].set_title('PDF of '+para_error, fontsize=20)\n",
    "                ax[1].legend(prop={'size': 15})\n",
    "                \n",
    "                \n",
    "#                 bins = np.arange(0,350,1000)\n",
    "#                 sns.distplot(net['CRBs_validation'][args[-100:],paraerror], hist=True, kde=True,  bins=int(180/5), color = 'blue', \n",
    "#                              hist_kws={'edgecolor':'black'}, kde_kws={'linewidth': 4}, \n",
    "#                              label='Keeping the 100 samples with highest relative error', ax=ax[2])\n",
    "                \n",
    "                \n",
    "                #if net['CRBrequired']\n",
    "#                 sns.distplot(net['CRBs_validation'][:,paraerror], hist=True, kde=True, \n",
    "#                              color = 'red', \n",
    "#                              hist_kws={'edgecolor':'black'}, kde_kws={'linewidth': 4},\n",
    "#                              label='On the whole validation dataset',ax=ax[2])\n",
    "                ax[2].set_xlabel('CRB', fontsize=15)\n",
    "                ax[2].set_title('PDF of the CRB on '+para_error, fontsize=20)\n",
    "                ax[2].legend(prop={'size': 15})\n",
    "                fig.subplots_adjust(hspace=0.4)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "        elif type_plot == 'gradients wrt loss':\n",
    "            sns.set_style(\"ticks\")        \n",
    "            fig , ax = plt.subplots()\n",
    "            plt.plot(net['losses'],net['gradients'])\n",
    "            ax.set_xlabel('Training loss per epoch')\n",
    "            ax.set_ylabel('Average of the gradient norm per epoch')\n",
    "            plt.title('Norm of the gradients of the parameters wrt the training loss',size=15)\n",
    "            plt.show()\n",
    "            \n",
    "        elif type_plot == 'samples':\n",
    "            sampled_points = net['samples']\n",
    "            plt.scatter(np.log10(sampled_points[:,2]),np.log10(sampled_points[:,1]))\n",
    "            plt.xlabel('log(T2)')\n",
    "            plt.ylabel('log(T1)')\n",
    "            plt.title('Points sampled during training')\n",
    "            plt.show()\n",
    "\n",
    "        elif type_plot ==  'loss':\n",
    "            plt.figure(figsize=(12,5))\n",
    "            plt.style.use('seaborn-whitegrid')\n",
    "            train_loss = (net['losses'])[indice:]\n",
    "            train_loss = moving_average(train_loss, n=mvavg)\n",
    "            size = train_loss.shape[0]\n",
    "            val_loss = moving_average((net['losses_validation'])[indice:], n=mvavg)\n",
    "            plt.subplot()\n",
    "            absc = [mvavg+indice + j for j in range(size)]\n",
    "            plt.plot(absc,train_loss, label='training')\n",
    "            plt.plot(absc, val_loss, label='validation')\n",
    "            plt.legend()\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.title('Loss along epochs',size=20)\n",
    "            plt.show()\n",
    "\n",
    "PLOT = widgets.Output()\n",
    "PLOT.clear_output()\n",
    "\n",
    "options = {'settings', 'error', 'loss', 'relative errors', 'absolute errors','absolute errors over CRBs', 'NN VS NLLS and CRB', 'gradients wrt loss'}\n",
    "options.update({'first_layer', 'Singular values projection layer', 'Basis functions for the projection subspace'})\n",
    "\n",
    "dropdown_type = widgets.Dropdown(options = options, value='settings', description='Visualization : ', style=style, layout=layout)\n",
    "dropdown_network = widgets.Dropdown(options = fnetworks  , description='Chosen network: ', style=style, layout=layout)\n",
    "dropdown_indice = widgets.BoundedIntText(min=0, max=100000, value=1, step=1, description='Starting epoch: ', style=style, layout=layout)\n",
    "mv_avg = widgets.BoundedIntText(min=1, max=100000, value=1, step=1, description='Number of epochs for moving average: ', style=style, layout=layout)\n",
    "dropdown_folder = widgets.Dropdown(\n",
    "                    options=next(os.walk('../noise_files'))[1],\n",
    "                    description='Folder nlls:', style=style, layout=layout)\n",
    "dropdown_num = widgets.BoundedIntText(\n",
    "                    value=0,\n",
    "                    description='Number of the fingerprint to study:',\n",
    "                    disabled=False,\n",
    "                    min=0,\n",
    "                    style=style, layout=layout)\n",
    "dropdown_freqcut = widgets.FloatText(\n",
    "                    value=10000,\n",
    "                    description='Cut frequency:',\n",
    "                    disabled=False,\n",
    "                    min=0,\n",
    "                    style=style, layout=layout)\n",
    "dropdown_para_abs = widgets.Select(\n",
    "                    options=paramtoname.values(),\n",
    "                    value='m0s', \n",
    "                    description='Parameter in the x axis:',\n",
    "                    disabled=False,\n",
    "                    style=style, layout=layout)\n",
    "\n",
    "dropdown_para_ordo = widgets.Select(\n",
    "                    options=paramtoname.values(),\n",
    "                    value='T1', \n",
    "                    description='Parameter in the y axis:',\n",
    "                    disabled=False,\n",
    "                    style=style, layout=layout)\n",
    "\n",
    "dropdown_para_error = widgets.Select(\n",
    "                    options=paramtoname.values(),\n",
    "                    value='m0s', \n",
    "                    description='Parameter for the error:',\n",
    "                    disabled=False,\n",
    "                    style=style, layout=layout)\n",
    "\n",
    "def print_form(**func_kwargs):\n",
    "    if i.children[1].value in ['relative errors','loss','absolute errors','absolute errors over CRBs']:\n",
    "        return {'Network': i.children[0].value,\n",
    "                'Type': i.children[1].value,\n",
    "                'Mv Avg': i.children[2].value,\n",
    "                'Indice': i.children[3].value}\n",
    "    elif i.children[1].value == 'NN VS NLLS and CRB':\n",
    "        return {'Network': i.children[0].value,\n",
    "                'Type': i.children[1].value,\n",
    "                'Folder': i.children[2].value,\n",
    "                'Num': i.children[3].value}\n",
    "    elif i.children[1].value == 'Basis functions for the projection subspace':\n",
    "        return {'Network': i.children[0].value,\n",
    "                'Type': i.children[1].value,\n",
    "                'Freqcut': i.children[2].value}\n",
    "    elif i.children[1].value == 'error':\n",
    "        return {'Network': i.children[0].value,\n",
    "                'Type': i.children[1].value,\n",
    "                'paraabs': i.children[2].value,\n",
    "                'paraordo': i.children[3].value,                \n",
    "                'paraerror': i.children[4].value}\n",
    "\n",
    "    else:\n",
    "        return {'Network': i.children[0].value,\n",
    "                'Type': i.children[1].value}\n",
    "        \n",
    "\n",
    "def for_mv_avg(plottype):\n",
    "    if plottype.new in ['relative errors','loss', 'absolute errors','absolute errors over CRBs']:\n",
    "        new_i = widgets.interactive(print_form, network=dropdown_network, plottype=dropdown_type, mvavg=mv_avg, indice=dropdown_indice)\n",
    "        i.children = new_i.children\n",
    "    elif plottype.new == 'NN VS NLLS and CRB':\n",
    "        new_i = widgets.interactive(print_form, network=dropdown_network, plottype=dropdown_type, \n",
    "                                    folder=dropdown_folder, num=dropdown_num)\n",
    "        i.children = new_i.children\n",
    "    elif plottype.new == 'Basis functions for the projection subspace':\n",
    "        new_i = widgets.interactive(print_form, network=dropdown_network, plottype=dropdown_type, \n",
    "                                    freqcut=dropdown_freqcut)\n",
    "        i.children = new_i.children\n",
    "    elif plottype.new == 'error':\n",
    "        new_i = widgets.interactive(print_form, network=dropdown_network, plottype=dropdown_type, \n",
    "                                    para_abs=dropdown_para_abs, para_ordo=dropdown_para_ordo, para_error=dropdown_para_error)\n",
    "        i.children = new_i.children\n",
    "    else:\n",
    "        new_i = widgets.interactive(print_form, network=dropdown_network, plottype=dropdown_type)\n",
    "        i.children = new_i.children\n",
    "dropdown_type.observe(for_mv_avg, 'value')\n",
    "\n",
    "button = widgets.Button(description=\"CLICK HERE to change the network or plot !\", layout=widgets.Layout(width='30%', height='80px'))\n",
    "def on_button_clicked(b):\n",
    "    net = torch.load(join('../save_networks_offline',dropdown_network.value),map_location='cpu')\n",
    "    common_filtering(net, dropdown_network.value, dropdown_type.value, mvavg=mv_avg.value, indice=dropdown_indice.value,\n",
    "                    folder=dropdown_folder.value, num=dropdown_num.value, freqcut = dropdown_freqcut.value,\n",
    "                    para_abs=dropdown_para_abs.value, para_ordo=dropdown_para_ordo.value, para_error=dropdown_para_error.value)\n",
    "\n",
    "i = widgets.interactive(print_form, network=dropdown_network, plottype=dropdown_type)\n",
    "button.on_click(on_button_clicked)\n",
    "input_widgets = widgets.HBox([i, button], layout=item_layout)\n",
    "tab = widgets.Tab([PLOT], layout=item_layout)\n",
    "dashboard = widgets.VBox([input_widgets, PLOT])\n",
    "display(dashboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = importlib.import_module('MRF.models.full_joint_deep3')\n",
    "\n",
    "with open('../settings_files_offline/settings_32.pkl', 'rb') as f:\n",
    "        settings = pickle.load(f)\n",
    "        training_parameters = Training_parameters(settings['batch_size'], 1, settings['nb_epochs'], settings['params'], settings['normalization'])\n",
    "        projection = Projection(settings['start_by_projection'], settings['dimension_projection'], settings['initialization'], settings['normalization'])\n",
    "        data_class = Data_class(training_parameters, settings['noise_type'], settings['noise_level'], \n",
    "                                       settings['minPD'], settings['maxPD'], settings['url_file'])\n",
    "        validation_settings = {'validation': settings['validation'],'small_validation_size': settings['small_validation_size'], 'validation_size': settings['validation_size']}\n",
    "        netw = model.model(projection=projection,nb_params=len(settings['params']))\n",
    "        device = torch.device('cpu')\n",
    "        netw.load_state_dict(net['NN'])\n",
    "        print(len(list(netw.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load(join('../save_networks_offline','network_crb-gauss-ligo'),map_location='cpu')\n",
    "model = importlib.import_module('MRF.models.'+net['name_model'])\n",
    "with open('../settings_files_offline/settings_crb-gauss-ligo.pkl', 'rb') as f:\n",
    "    settings = pickle.load(f)\n",
    "    training_parameters = Training_parameters(settings['batch_size'], 1, settings['nb_epochs'], settings['params'], settings['normalization'])\n",
    "    projection = Projection(settings['start_by_projection'], settings['dimension_projection'], settings['initialization'], settings['normalization'])\n",
    "    data_class = Data_class(training_parameters, settings['noise_type'], settings['noise_level'], \n",
    "                                   settings['minPD'], settings['maxPD'], settings['url_file'])\n",
    "    validation_settings = {'validation': settings['validation'],'small_validation_size': settings['small_validation_size'], 'validation_size': settings['validation_size']}\n",
    "    netw = model.model(projection=projection,nb_params=len(settings['params']))\n",
    "    device = torch.device('cpu')\n",
    "    netw.load_state_dict(net['NN'])\n",
    "    netw.eval()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg = np.argsort(np.array(net['CRBs_validation'][:,0]))\n",
    "\n",
    "print(net['CRBs_validation'][arg,0])\n",
    "\n",
    "plt.hist(net['params_validation'][arg[:50],0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MRF.simulate_signal import simulation\n",
    "model = importlib.import_module('MRF.models.ligo')\n",
    "net = torch.load(join('../save_networks_offline','network_crb-gauss-ligo'),map_location='cpu')\n",
    "\n",
    "\n",
    "with open('../settings_files_offline/settings_crb-gauss-ligo.pkl', 'rb') as f:\n",
    "    settings = pickle.load(f)\n",
    "    training_parameters = Training_parameters(settings['batch_size'], 1, settings['nb_epochs'], settings['params'], settings['normalization'])\n",
    "    projection = Projection(settings['start_by_projection'], settings['dimension_projection'], settings['initialization'], settings['normalization'])\n",
    "    data_class = Data_class(training_parameters, settings['noise_type'], settings['noise_level'], \n",
    "                                   settings['minPD'], settings['maxPD'], settings['nb_files'], settings['path_files'])\n",
    "    validation_settings = {'validation': settings['validation'],'small_validation_size': settings['small_validation_size'], 'validation_size': settings['validation_size']}\n",
    "    netw = model.model(projection=projection,nb_params=len(settings['params']))\n",
    "    device = torch.device('cpu')\n",
    "    netw.load_state_dict(net['NN'])\n",
    "    netw.eval()\n",
    "    estimation = Network(settings['model'], settings['loss'], training_parameters, settings['save_name'], data_class, validation_settings, projection=projection)\n",
    "\n",
    "    prms= [0.3,1,0.1,100,1e-2]\n",
    "\n",
    "    y,dy = simulation.simulate_MT_ODE(data_class.x, data_class.TR, data_class.t, prms[0], prms[1], prms[2], prms[3], prms[1], prms[4])\n",
    "\n",
    "    prms= [0.34,1,0.1,100,1e-2]\n",
    "\n",
    "    y2,dy = simulation.simulate_MT_ODE(data_class.x, data_class.TR, data_class.t, prms[0], prms[1], prms[2], prms[3], prms[1], prms[4])\n",
    "\n",
    "\n",
    "    plt.plot(y[:,0])    \n",
    "    plt.plot(y2[:,0])\n",
    "    \n",
    "    print(  np.dot(y[:,0],y2[:,0]) / np.linalg.norm(y2[:,0]) / np.linalg.norm(y[:,0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones((5,3))\n",
    "\n",
    "print(torch.norm(a, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Without':\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
